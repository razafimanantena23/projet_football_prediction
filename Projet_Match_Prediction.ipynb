{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69093e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d000a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import packages\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aae1427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define the urlpage\n",
    "urlpage = 'https://www.premierleague.com/tables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b64150",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define a function to get the web page and subtract the part of the html codes we need (function n°1)\n",
    "\n",
    "def get_page(urlpage,element,html_id):\n",
    "    # Get page in html\n",
    "    req = urllib3.PoolManager()\n",
    "    res = req.request('GET', urlpage)\n",
    "    row_html = BeautifulSoup(res.data, 'html.parser')\n",
    "    \n",
    "    # Return elements that matched the html class in a list\n",
    "    All_leagues = row_html.find_all('main' ,id= \"mainContent\")\n",
    "    \n",
    "    #Split All_championnat to get each championship\n",
    "    by_league = str(All_leagues).split('<div class=\"tableCompetitionExplainedContainer\"></div>')\n",
    "    \n",
    "    #Return elements and class for the current championship (2023)\n",
    "    Premier_league_23= by_league[0]\n",
    "    \n",
    "    return Premier_league_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's test the function n°1\n",
    "\n",
    "Premier_league_23= get_page(urlpage,\n",
    "                        'main', \"mainContent\")\n",
    "print(Premier_league_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07efcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Let's define a function to get informations on each team (function n°2)\n",
    "\n",
    "def extract_team_23_stats(Premier_league_23, team):\n",
    "    team_real= team.title()\n",
    "    pattern = r'data-filtered-table-row-name=\"{}\"'.format(team_real)\n",
    "    match = re.search(pattern, Premier_league_23)\n",
    "    start= match.start()\n",
    "    end = Premier_league_23.index('<tr class=\"expandable\"', start)\n",
    "    team_data_23 = Premier_league_23[start:end]\n",
    "    \n",
    "    position = int(re.findall('data-position=\"(.*?)\">', str(team_data_23))[0])\n",
    "    data =  re.findall(r'<td.*?>(\\d+)<\\/td>', team_data_23)\n",
    "    match_played =int(data[0].strip('<td>').strip('</td>'))\n",
    "    points = int(re.search(r'<td class=\"points\">\\d+</td>', team_data_23).group().strip('<td class=\"points\">').strip('</td>'))\n",
    "    wins = int(data[1].strip('<td>').strip('</td>'))\n",
    "    loses = int(data[3].strip('<td>').strip('</td>'))\n",
    "    drawns = int(data[2].strip('<td>').strip('</td>'))\n",
    "    goals_for= int(data[4].strip('<td>').strip('</td>'))\n",
    "    goals_against= int(data[5].strip('<td>').strip('</td>'))\n",
    "\n",
    "    team_stats = {'position': position,'match_played': match_played,'points': points,'wins': wins,'loses': loses,'drawns': drawns,'goals_for': goals_for,\n",
    "        'goals_against': goals_against\n",
    "    }\n",
    "\n",
    "    return team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's test the function n°2\n",
    "\n",
    "extract_team_23_stats(Premier_league_23, \"manchester city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e450a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define our second urlpage for injured and suspended players\n",
    "\n",
    "urlpage_2 = 'https://www.foot-direct.com/angleterre/premier-league/blessures-et-suspensions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdace720",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define a function to get the web page and subtract the part of the html codes we need (function n°3)\n",
    "\n",
    "def get_page(urlpage_2,element,html_class):\n",
    "    # Get page in html\n",
    "    req_2 = urllib3.PoolManager()\n",
    "    res_2 = req_2.request('GET', urlpage_2)\n",
    "    row_html_2 = BeautifulSoup(res_2.data, 'html.parser')\n",
    "    \n",
    "    # Return elements that matched the html class in a list\n",
    "    injured_content = row_html_2.find_all(element , class_= html_class)\n",
    "    return(injured_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152714d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test the function n°3\n",
    "\n",
    "injured_content= get_page(urlpage_2, 'div', \"content\")\n",
    "print(injured_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f63a3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First create a list for all teams with injured players\n",
    "teams = re.findall('<a class=\"flex--center2\" href=\"/equipe/(.*?)\">', str(injured_content))\n",
    "    \n",
    "### If the name of the teamm is composed by \"-\", replace it by espace\n",
    "for i in range(len(teams)):\n",
    "    teams[i]= teams[i].replace(\"-\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9248f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define a function to get all injured players for each team (function n°4)\n",
    "\n",
    "def player_injured_by_team (team_name):\n",
    "    team_name= team_name.lower()\n",
    "       \n",
    "    ## If teams not in the teams's list, return \"team is not in the list\"\n",
    "    \n",
    "    if team_name not in teams:\n",
    "        print(\"team is not in the list\")\n",
    "    \n",
    "    ## Else, create a row list for each team and apply the boucle while to obtain in a list, all injured players\n",
    "    \n",
    "    else:\n",
    "        player_injured_team= dict() ## To create the dictionary\n",
    "        team_injured_content = str(injured_content).split('<div class=\"card card--team marginTop--2')[1:]\n",
    "        \n",
    "        players_injured= []\n",
    "        i =-1\n",
    "        \n",
    "        while len(players_injured) < len(team_injured_content):\n",
    "            i+=1\n",
    "            player_injured_each_team = re.findall('<a href=\"/joueur/(.*?)\">', str(team_injured_content[i]))\n",
    "            players_injured.append(player_injured_each_team)\n",
    "        numero= teams.index(team_name)\n",
    "        \n",
    "        ## Dictionnary for the injured players of a team\n",
    "        player_injured_team.update({teams[numero] : players_injured[numero]})\n",
    "        return player_injured_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7290788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the function n°4\n",
    "player_injured_by_team ('Arsenal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "142c9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage_3= 'https://fr.besoccer.com/competition/classement/premier/2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a989a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define a function to get the web page and subtract the part of the html codes we need (function n°4)\n",
    "\n",
    "def get_page(urlpage_3,element,html_class):\n",
    "    # Get page in html\n",
    "    req_3 = urllib3.PoolManager()\n",
    "    res_3 = req_3.request('GET', urlpage_3)\n",
    "    row_html_3 = BeautifulSoup(res_3.data, 'html.parser')\n",
    "    \n",
    "    # Return elements that matched the html class in a list\n",
    "    Premier_league_22 = row_html_3.find_all(element , class_= html_class)\n",
    "    return(Premier_league_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test the function n°4\n",
    "\n",
    "Premier_league_22= str(get_page(urlpage_3, 'tr', 'row-body'))\n",
    "print(Premier_league_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2887e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def extract_team_22_stats(Premier_league_22, team):\n",
    "    teams = re.findall('<span class=\"team-name\">(.*?)</span>', str(Premier_league_22))\n",
    "    position= (teams.index(team)+1)\n",
    "    start = Premier_league_22.find(team)\n",
    "    end = Premier_league_22.index(\"</tr>\", start)\n",
    "    team_data_22 = Premier_league_22[start:end]\n",
    "    \n",
    "    match_played= 38\n",
    "    data = [int(s) for s in re.findall(r'<td.*?>(\\d+)</td>', team_data_22)]\n",
    "    points= data[0]\n",
    "    wins= data [1]\n",
    "    drawns= data [2]\n",
    "    loses =data [3]\n",
    "    goals_for = data [4]\n",
    "    goals_against = data [5]\n",
    "\n",
    "    team_stats22 = {'match_played': match_played,'position': position,'points': points,\n",
    "                    'wins': wins,'loses': loses ,'drawns':  drawns,'goals_for': goals_for,\n",
    "        'goals_against':goals_against\n",
    "    }\n",
    "\n",
    "    return team_stats22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's test function 5\n",
    "extract_team_22_stats(Premier_league_22, \"Arsenal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9cd24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage_4= 'https://fr.besoccer.com/competition/classement/premier/2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "786236de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define a function to get the web page and subtract the part of the html codes we need (function n°5)\n",
    "\n",
    "def get_page(urlpage_4,element,html_class):\n",
    "    # Get page in html\n",
    "    req_4 = urllib3.PoolManager()\n",
    "    res_4 = req_4.request('GET', urlpage_4)\n",
    "    row_html_4 = BeautifulSoup(res_4.data, 'html.parser')\n",
    "    \n",
    "    # Return elements that matched the html class in a list\n",
    "    Premier_league_21 = row_html_4.find_all(element , class_= html_class)\n",
    "    return(Premier_league_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test the function n°5\n",
    "\n",
    "Premier_league_21= str(get_page(urlpage_4, 'tr', 'row-body'))\n",
    "print(Premier_league_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df86077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def extract_team_21_stats(Premier_league_21, team):\n",
    "    teams = re.findall('<span class=\"team-name\">(.*?)</span>', str(Premier_league_21))\n",
    "    position= (teams.index(team)+1)\n",
    "    start = Premier_league_21.find(team)\n",
    "    end = Premier_league_21.index(\"</tr>\", start)\n",
    "    team_data_21 = Premier_league_21[start:end]\n",
    "    \n",
    "    match_played= 38\n",
    "    data = [int(s) for s in re.findall(r'<td.*?>(\\d+)</td>', team_data_21)]\n",
    "    points= data[0]\n",
    "    wins= data [1]\n",
    "    drawns= data [2]\n",
    "    loses =data [3]\n",
    "    goals_for = data [4]\n",
    "    goals_against = data [5]\n",
    "\n",
    "    team_stats21 = {'match_played': match_played,'position': position,'points': points,\n",
    "                    'wins': wins,'loses': loses ,'drawns':  drawns,'goals_for': goals_for,\n",
    "        'goals_against':goals_against\n",
    "    }\n",
    "\n",
    "    return team_stats21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde70bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's test function 6\n",
    "extract_team_21_stats(Premier_league_21, \"Arsenal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffef5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage_5= 'https://fr.besoccer.com/competition/classement/premier/2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a04ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's define a function to get the web page and subtract the part of the html codes we need (function n°7)\n",
    "\n",
    "def get_page(urlpage_5,element,html_class):\n",
    "    # Get page in html\n",
    "    req_5 = urllib3.PoolManager()\n",
    "    res_5 = req_5.request('GET', urlpage_5)\n",
    "    row_html_5 = BeautifulSoup(res_5.data, 'html.parser')\n",
    "    \n",
    "    # Return elements that matched the html class in a list\n",
    "    Premier_league_20 = row_html_5.find_all(element , class_= html_class)\n",
    "    return(Premier_league_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test the function n°7\n",
    "\n",
    "Premier_league_20= str(get_page(urlpage_5, 'tr', 'row-body'))\n",
    "print(Premier_league_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "619c2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def extract_team_20_stats(Premier_league_20, team):\n",
    "    teams = re.findall('<span class=\"team-name\">(.*?)</span>', str(Premier_league_20))\n",
    "    position= (teams.index(team)+1)\n",
    "    start = Premier_league_20.find(team)\n",
    "    end = Premier_league_20.index(\"</tr>\", start)\n",
    "    team_data_20 = Premier_league_20[start:end]\n",
    "    \n",
    "    match_played= 38\n",
    "    data = [int(s) for s in re.findall(r'<td.*?>(\\d+)</td>', team_data_20)]\n",
    "    points= data[0]\n",
    "    wins= data [1]\n",
    "    drawns= data [2]\n",
    "    loses =data [3]\n",
    "    goals_for = data [4]\n",
    "    goals_against = data [5]\n",
    "\n",
    "    team_stats20 = {'match_played': match_played,'position': position,'points': points,\n",
    "                    'wins': wins,'loses': loses ,'drawns':  drawns,'goals_for': goals_for,\n",
    "        'goals_against':goals_against\n",
    "    }\n",
    "\n",
    "    return team_stats20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67507516",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_played': 38,\n",
       " 'position': 8,\n",
       " 'points': 56,\n",
       " 'wins': 14,\n",
       " 'loses': 10,\n",
       " 'drawns': 14,\n",
       " 'goals_for': 56,\n",
       " 'goals_against': 48}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's test function 6\n",
    "extract_team_20_stats(Premier_league_20, \"Arsenal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6776c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
